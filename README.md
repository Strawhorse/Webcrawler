# Webcrawler
 Webcrawler with simple search function for keywords and hyperlinks built in Java 17 and jsoup package

No workaround for site protection from spiders, something that could be dealt with later

To be done:
- Retrieve a web page (we'll call it a document) from a website
- Collect all the links on that document
- Collect all the words on that document
- See if the word we're looking for is contained in the list of words
- Visit the next link
- Keep track of pages visited
- Limit the number of pages to search


Found good information at:
- https://docs.oracle.com/javase/8/docs/api/org/w3c/dom/Document.html
- http://www.netinstructions.com/how-to-make-a-simple-web-crawler-in-java/#google_vignette


Experiencing some issues with the imports of jsoup - resolved issue by working on docs:
https://jsoup.org/apidocs/org/jsoup/select/Elements.html
https://jsoup.org/cookbook/input/load-document-from-url








